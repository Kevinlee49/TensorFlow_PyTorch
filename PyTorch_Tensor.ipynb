{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor\n",
        "##### 텐서는 배열이나 행렬과 매우 유사한 특수한 자료구조이다. 파이토치에서는 텐서를 사용하여 모델의 input, output 그리고 모델의 매개변수들을 encode 한다.\n",
        "##### 텐서는 GPU나 다른 하드웨어 가속기에서 실행할 수 있다는 점만 제외하면 Numpy 의 ndarray 와 비슷하다. \n",
        "##### 텐서는 자동미분(automatic differentiation)에 최적화되어 있다."
      ],
      "metadata": {
        "id": "OD5a2-IGcxjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UqhYFTohYbfF"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서 초기화\n",
        "###### 1) 데이터로부터 직접 생성하기\n",
        "###### 2) NumPy 배열로부터 생성하기 (반대로도 가능)\n",
        "###### 3) 다른 텐서로부터 생성하기\n",
        "###### 4) 무작위(random) or 상수(constant) 값을 사용하기"
      ],
      "metadata": {
        "id": "JwVZ9PUUdhvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "data = [[1,2],[3,4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "C8gkZdUBYfxp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "47tgucVDYfuz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "x_ones = torch.ones_like(x_data) # x_data 의 속성을 유지\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype = torch.float) # x_data의 속성을 덮어씀\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8sMa3MBYfrZ",
        "outputId": "fb14ae2a-6a88-4d82-805a-cb3acd63a41c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.1331, 0.9542],\n",
            "        [0.7027, 0.9507]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### shape 은 텐서의 차원을 나타내는 tuple이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "fxi3f9UZeSUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.rand(shape)\n",
        "zeros_tensor = torch.rand(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor}\\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor}\\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_T7VAE0YfqV",
        "outputId": "a9799888-3f45-4bbb-b96b-4aa87118e266"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.2772, 0.2153, 0.4699],\n",
            "        [0.5677, 0.8484, 0.5066]])\n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[0.0954, 0.9332, 0.9592],\n",
            "        [0.5894, 0.0264, 0.4745]])\n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0.9873, 0.0749, 0.6203],\n",
            "        [0.5208, 0.0211, 0.7792]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 텐서의 속성은 텐서의 shape, datatype(자료형) 및 어느 장치에 저장되는지를 나타낸다."
      ],
      "metadata": {
        "id": "2u3c2gRGeoOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\\n\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\\n\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iCMQSdkYfnj",
        "outputId": "2b3acda4-0caf-4d25-8233-05cb04cf4071"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "\n",
            "Datatype of tensor: torch.float32\n",
            "\n",
            "Device tensor is stored on: cpu\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서 연산(Tensor Operation)\n",
        "\n",
        "\n",
        "*   각 연산들은 GPU에서 실행가능(CPU보다 빠름)\n",
        "*   기본적으로 텐서는 CPU에 생성되는데 .to 를 사용하면 GPU 의 availability 를 확인하고 GPU 로 텐서를 이동할 수 있음. \n",
        "*   장치들 간에 큰 텐서들을 복사하는 것은 시간과 메모리 측면에서 비용이 많이듦.\n",
        "\n"
      ],
      "metadata": {
        "id": "gD6N5tmke-ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")"
      ],
      "metadata": {
        "id": "1CRQyMQbYuY_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4,4)\n",
        "print(f\"First row: {tensor[0]} \")\n",
        "print(f\"First column: {tensor[:,0]} \")\n",
        "print(f\"Last column: {tensor[:,-1]} \")\n",
        "tensor[:,1] = 0\n",
        "print(tensor)\n",
        "print(f\"First row: {tensor[0]} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kG377y1YuVl",
        "outputId": "b78399e9-645d-4b65-eeb5-ed3d61e4c04a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.]) \n",
            "First column: tensor([1., 1., 1., 1.]) \n",
            "Last column: tensor([1., 1., 1., 1.]) \n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n",
            "First row: tensor([1., 0., 1., 1.]) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor merge\n",
        "##### torch.cat() vs torch.stack()\n",
        "##### torch.cat() 은 (4,4) shape 의 tensor 3개를 concatenation -> result 텐서는 (12,4) shape 을 가짐\n",
        "##### torch.stack() 은 말그대로 스택을 쌓는것, (4,4) shape 의 tensor 3개를 stack -> result 텐서는 (3,4,4) 의 크기를 갖게됨."
      ],
      "metadata": {
        "id": "GbpPLzjig5zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RjRRmdqi0qm",
        "outputId": "e7bcea3b-f440-4d61-cd6b-00900650f1c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim = 0)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1-tiiK-YflD",
        "outputId": "9309bae5-471b-4372-841e-c23b0bfb9316"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.stack([tensor, tensor, tensor], dim=0)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCFxFxbhTu-",
        "outputId": "a385ced2-e959-492b-b13c-6b97a23c7ac7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]],\n",
            "\n",
            "        [[1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.],\n",
            "         [1., 0., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arithmetic Operations"
      ],
      "metadata": {
        "id": "IYCdys86jez6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = tensor @ tensor.T\n",
        "print(tensor.T)\n",
        "print(f\"y1: {y1} \\n\")\n",
        "\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "print(f\"y2: {y2} \\n\")\n",
        "print(f\"y3: {y3} \\n\")\n",
        "\n",
        "\n",
        "z1 = tensor * tensor \n",
        "z2 = tensor.mul(tensor)\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor,tensor, out=z3)\n",
        "\n",
        "print(f\"z1: {z1} \\n\")\n",
        "print(f\"z2: {z2} \\n\")\n",
        "print(f\"z3: {z3} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeobqEKhYfez",
        "outputId": "d635264d-5074-4913-b7c6-d4e2f2a848c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "y1: tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) \n",
            "\n",
            "y2: tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) \n",
            "\n",
            "y3: tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]]) \n",
            "\n",
            "z1: tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "z2: tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "z3: tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPpLETXnYyaJ",
        "outputId": "f3da602c-96e3-4dc5-e977-da7d96810845"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### in-place(바꿔치기) operation - 연산 결과를 피연산자(operand)에 저장하는 연산 \n",
        "ex) x.copy_(y) , x.t_() \n",
        "\n",
        "##### in-place operation 은 메모리를 일부 절약하지만, history 가 즉시 삭제되어 derivative calculation 에 문제가 발생할 수 있음, 그래서 사용을 권장하지 않는다."
      ],
      "metadata": {
        "id": "yakAC0L1jq52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor) # NOTE *** - in-place operation is~~~"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtnJdrT2YyZc",
        "outputId": "905fbc5b-1cdf-44da-d440-fc084f548532"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\\n\")\n",
        "\n",
        "t.add_(2)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln0OHAmeYyWL",
        "outputId": "0bc726e5-2fc0-42eb-f400-0ff0b8afc919"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n",
            "\n",
            "t: tensor([3., 3., 3., 3., 3.])\n",
            "n: [3. 3. 3. 3. 3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)\n",
        "\n",
        "print(f\"n: {n}\")\n",
        "print(f\"t: {t} \\n\")\n",
        "\n",
        "np.add(n, 5, out = n)\n",
        "print(f\"n: {n}\")\n",
        "print(f\"t: {t}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt5DUQnFYyVF",
        "outputId": "0064fd7a-c4d1-4985-aba5-2fd72ea8de21"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n: [1. 1. 1. 1. 1.]\n",
            "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64) \n",
            "\n",
            "n: [6. 6. 6. 6. 6.]\n",
            "t: tensor([6., 6., 6., 6., 6.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Gfn20ieYyR2"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}